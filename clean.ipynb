{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charming-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from os import makedirs\n",
    "from os import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import re\n",
    "#Habilitar autocomplete\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geological-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_cleanned(data):\n",
    "    resultados = []\n",
    "    lista=[]\n",
    "    #excecoes =  ['...','..','.','-']\n",
    "    tamanho = data['resultados'].shape[0] +1\n",
    "    \n",
    "    for i in range(tamanho):\n",
    "        #resultados.append(dt_result.iloc[0:i][0][0]['series'][0]['serie'])\n",
    "        if i == 0:\n",
    "            result = list(data['resultados'].iloc[:0])\n",
    "        else:\n",
    "            result = list(data['resultados'].iloc[i-1:i])\n",
    "        if len(result) > 0:\n",
    "            valores = result[0][0]['series'][0]['serie']\n",
    "            if len(valores) == 1:\n",
    "                resultados.append(valores)\n",
    "            else:\n",
    "                aux2 = list(valores.items())\n",
    "                for i in aux2:\n",
    "                     resultados.append(i)\n",
    "#                     if i[1] not in excecoes:\n",
    "#                         resultados.append(i)\n",
    "\n",
    "    for i in resultados:\n",
    "        if type(i) is dict:\n",
    "            lista.append(i.items())\n",
    "        elif type(i) is list:\n",
    "            lista.append(i)\n",
    "    \n",
    "    col_ano_valor = pd.DataFrame(lista,columns=['ano_valor'])\n",
    "    return(col_ano_valor)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "available-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrer cidades na categoria\n",
    "def read_cities(dir_cities,path):\n",
    "    for city in dir_cities[:1]:\n",
    "        print(\"\\nCIDADE =>\",city)\n",
    "        path_cities = path+'/'+str(city)+'/'\n",
    "        dir_files = [f for f in listdir(path_cities) if isfile(join(path_cities, f))]\n",
    "        print(\"Path =>\",path_cities)\n",
    "        print(\"arquivos =>\",dir_files[0:5])\n",
    "        #print(\"\\n\",dir_files)\n",
    "        # Percorrer arquivo diretÃ³rio\n",
    "        dt_city = pd.DataFrame()\n",
    "        for arq in dir_files:\n",
    "            arquivo = path_cities+'/'+arq\n",
    "            data = pd.read_json(arquivo)\n",
    "    #       Transformando json em DataFrame somente com os valores da pesquisa\n",
    "            new_data = export_cleanned(data)\n",
    "    #       Concatena os dados e exclui a coluna com o json \n",
    "            data = pd.concat([data,new_data],axis=1)\n",
    "            data = data.drop(columns=['resultados'])\n",
    "            #data = verify_concat(dt_city,data,path,arquivo)\n",
    "\n",
    "            dt_city = pd.concat([dt_city,data])\n",
    "            dt_city.index = [x for x in range(0,len(dt_city))]\n",
    "\n",
    "    #         output_name= re.sub(\".json\",\"\",arq)\n",
    "    #         output_name= path+\"/datacleanned/\"+output_name+\".xlsx\"\n",
    "        os.makedirs(path_cities+'/'+'datacleanned',exist_ok=True)    \n",
    "        out_name = path_cities+'/datacleanned/'+str(city)+'.xlsx'   \n",
    "        dt_city.to_excel(out_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "progressive-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', 'CD', 'SB']\n"
     ]
    }
   ],
   "source": [
    "path_database = './database/'\n",
    "dir_database_cat = [f for f in listdir(path_database) if listdir(join(path_database, f))]\n",
    "print(dir_database_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "amended-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___Categoria_[ AA ]_\n",
      "\n",
      "CIDADE => AMATURA\n",
      "Path => ./database/AA/AMATURA/\n",
      "arquivos => ['1279.json', '1280.json', '1306.json', '1307.json', '1315.json']\n",
      "\n",
      "___Categoria_[ CD ]_\n",
      "\n",
      "CIDADE => AMATURA\n",
      "Path => ./database/CD/AMATURA/\n",
      "arquivos => ['102.json', '103.json', '105.json', '107.json', '108.json']\n",
      "\n",
      "___Categoria_[ SB ]_\n",
      "\n",
      "CIDADE => AMATURA\n",
      "Path => ./database/SB/AMATURA/\n",
      "arquivos => ['1023.json', '1024.json', '1026.json', '1027.json', '1028.json']\n"
     ]
    }
   ],
   "source": [
    "for cat in dir_database_cat :\n",
    "    print(\"\\n___Categoria_[ {} ]_\".format(cat))\n",
    "    path_cidades=path_database+cat\n",
    "#     if cat != 'CD':\n",
    "    dir_cities = [f for f in listdir(path_cidades) if listdir(join(path_cidades, f))]\n",
    "    read_cities(dir_cities,'./database/'+cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-declaration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
