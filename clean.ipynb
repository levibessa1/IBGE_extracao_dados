{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nuclear-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from os import makedirs\n",
    "from os import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import re\n",
    "#Habilitar autocomplete\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "natural-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_cidades = './database/CD'\n",
    "# dir_cities = [f for f in listdir(path_cidades) if listdir(join(path_cidades, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "miniature-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_cleanned(data):\n",
    "    resultados = []\n",
    "    lista=[]\n",
    "    #excecoes =  ['...','..','.','-']\n",
    "    tamanho = data['resultados'].shape[0] +1\n",
    "    \n",
    "    for i in range(tamanho):\n",
    "        #resultados.append(dt_result.iloc[0:i][0][0]['series'][0]['serie'])\n",
    "        if i == 0:\n",
    "            result = list(data['resultados'].iloc[:0])\n",
    "        else:\n",
    "            result = list(data['resultados'].iloc[i-1:i])\n",
    "        if len(result) > 0:\n",
    "            valores = result[0][0]['series'][0]['serie']\n",
    "            if len(valores) == 1:\n",
    "                resultados.append(valores)\n",
    "            else:\n",
    "                aux2 = list(valores.items())\n",
    "                for i in aux2:\n",
    "                     resultados.append(i)\n",
    "#                     if i[1] not in excecoes:\n",
    "#                         resultados.append(i)\n",
    "\n",
    "    for i in resultados:\n",
    "        if type(i) is dict:\n",
    "            lista.append(i.items())\n",
    "        elif type(i) is list:\n",
    "            lista.append(i)\n",
    "    \n",
    "    col_ano_valor = pd.DataFrame(lista,columns=['ano_valor'])\n",
    "    return(col_ano_valor)\n",
    "    #print(frame)\n",
    "    #frame = pd.concat([data,resultados])\n",
    "    #print(frame.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "norwegian-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrer cidades na categoria\n",
    "def read_cities(dir_cities,path):\n",
    "    for city in dir_cities[:1]:\n",
    "        print(\"\\nCIDADE =>\",city)\n",
    "        path_cities = path+'/'+str(city)+'/'\n",
    "        dir_files = [f for f in listdir(path_cities) if isfile(join(path_cities, f))]\n",
    "        print(\"Path =>\",path_cities)\n",
    "        print(\"arquivos =>\",dir_files[0:5])\n",
    "        #print(\"\\n\",dir_files)\n",
    "        # Percorrer arquivo diretório\n",
    "        dt_city = pd.DataFrame()\n",
    "        for arq in dir_files:\n",
    "            arquivo = path_cities+'/'+arq\n",
    "            data = pd.read_json(arquivo)\n",
    "    #       Transformando json em DataFrame somente com os valores da pesquisa\n",
    "            new_data = export_cleanned(data)\n",
    "    #       Concatena os dados e exclui a coluna com o json \n",
    "            data = pd.concat([data,new_data],axis=1)\n",
    "            data = data.drop(columns=['resultados'])\n",
    "            #data = verify_concat(dt_city,data,path,arquivo)\n",
    "\n",
    "            dt_city = pd.concat([dt_city,data])\n",
    "            dt_city.index = [x for x in range(0,len(dt_city))]\n",
    "\n",
    "    #         output_name= re.sub(\".json\",\"\",arq)\n",
    "    #         output_name= path+\"/datacleanned/\"+output_name+\".xlsx\"\n",
    "#         os.makedirs(path_cities+'/'+'datacleanned',exist_ok=True)    \n",
    "#         out_name = path_cities+'/datacleanned/'+str(city)+'.xlsx'   \n",
    "#         dt_city.to_excel(out_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lined-penguin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', 'CD', 'SB']\n"
     ]
    }
   ],
   "source": [
    "path_database = './database/'\n",
    "dir_database_cat = [f for f in listdir(path_database) if listdir(join(path_database, f))]\n",
    "print(dir_database_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gothic-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "___Categoria_[ AA ]_\n",
      "\n",
      "CIDADE => AMATURA\n",
      "Path => ./database/AA/AMATURA/\n",
      "arquivos => ['1279.json', '1280.json', '1306.json', '1307.json', '1315.json']\n",
      "\n",
      "___Categoria_[ CD ]_\n",
      "\n",
      "CIDADE => AMATURA\n",
      "Path => ./database/CD/AMATURA/\n",
      "arquivos => ['102.json', '103.json', '105.json', '107.json', '108.json']\n",
      "\n",
      "___Categoria_[ SB ]_\n",
      "\n",
      "CIDADE => AMATURA\n",
      "Path => ./database/SB/AMATURA/\n",
      "arquivos => ['1023.json', '1024.json', '1026.json', '1027.json', '1028.json']\n"
     ]
    }
   ],
   "source": [
    "for cat in dir_database_cat :\n",
    "    print(\"\\n___Categoria_[ {} ]_\".format(cat))\n",
    "    path_cidades=path_database+cat\n",
    "#     if cat != 'CD':\n",
    "    dir_cities = [f for f in listdir(path_cidades) if listdir(join(path_cidades, f))]\n",
    "    read_cities(dir_cities,'./database/'+cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "assured-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_cidades = './database/CD'\n",
    "# dir_cities = [f for f in dir_database if listdir(join(path_cidades, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "natural-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def verify_concat(dt_city,new_dt,path,arq):\n",
    "#     dt_concated = pd.DataFrame()\n",
    "#     controle_repetidos = []\n",
    "\n",
    "#     if dt_city.shape[0] < 1:\n",
    "#         return (new_dt)\n",
    "#     else:\n",
    "#         for j in list(new_dt.id):\n",
    "#             for i in list(dt_city.id):      \n",
    "#                 if i == j and i not in controle_repetidos:\n",
    "#                     controle_repetidos.append(i)\n",
    "#                     print(controle_repetidos)\n",
    "#                     texto = dt_city.loc[dt_city['id'] == i]\n",
    "#                     #print(\"Encontrado em {} >> {}\".format(arq,texto))\n",
    "#                     os.makedirs(path+'/'+'datas_repeated',exist_ok=True)  \n",
    "#                     arquivo = path+'/datas_repeated/'+str(i)+'.txt'\n",
    "#                     #texto = \"Encontrado\"\n",
    "#                     with open(arquivo,'a') as f:\n",
    "#                         f.write('\\t'+arq)\n",
    "#                         f.write('\\n'+texto.to_csv(index=False))\n",
    "#                 else:\n",
    "#                     frame = new_dt.loc[new_dt['id']==j]\n",
    "#                     dt_concated = pd.concat([ dt_concated,frame])\n",
    "#                     dt_concated.reset_index()\n",
    "                \n",
    "#         return dt_concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "artistic-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #    Verifica dados duplicados e diferentes id's de pesquisa.\n",
    "# #    Armazena Dados Duplicados em um arquivo .xlsx\n",
    "# def verify_concat(dt_city,new_dt,path,arq):\n",
    "#     dt_concated = pd.DataFrame()\n",
    "#     controle_repetidos = []\n",
    "\n",
    "#     if dt_city.shape[0] < 1:\n",
    "#         return (new_dt)\n",
    "#     else:\n",
    "#         for i in list(dt_city.id):\n",
    "#             for j in list(new_dt.id):\n",
    "#                 if i == j:\n",
    "#                     if i in controle_repetidos:\n",
    "#                         # já foi escrito no arquivo de controle\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         controle_repetidos.append(i)\n",
    "#                         texto = dt_city.loc[dt_city['id'] == i]\n",
    "#                         #print(\"Encontrado em {} >> {}\".format(arq,texto))\n",
    "#                         os.makedirs(path+'/'+'datas_repeated',exist_ok=True)  \n",
    "#                         arquivo = path+'/datas_repeated/'+str(i)+'.txt'\n",
    "#                         #texto = \"Encontrado\"\n",
    "#                         with open(arquivo,'a') as f:\n",
    "#                             f.write('\\t'+arq)\n",
    "#                             f.write('\\n'+texto.to_csv(index=False))\n",
    "#                 else:\n",
    "#                     frame = new_dt.loc[new_dt['id']==j]\n",
    "#                     dt_concated = pd.concat([ dt_concated,frame])\n",
    "#                     dt_concated.reset_index()\n",
    "                \n",
    "#         return dt_concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-transmission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
